<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Linear Regression | Artifex Spring 2022</title>
  <meta name="description" content="Class materials for Paul 520." />
  <meta name="generator" content="bookdown 0.25 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Linear Regression | Artifex Spring 2022" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Class materials for Paul 520." />
  <meta name="github-repo" content="openscapes/series" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Linear Regression | Artifex Spring 2022" />
  
  <meta name="twitter:description" content="Class materials for Paul 520." />
  

<meta name="author" content="David Reynolds" />


<meta name="date" content="2022-04-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="setup.html"/>
<link rel="next" href="ts.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="lib/css/bootstrap.min.css" type="text/css" />
<link rel="stylesheet" href="lib/css/style.css" type="text/css" />
<link rel="stylesheet" href="lib/css/lesson.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">UNH Artifex</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Welcome<span></span></a></li>
<li class="chapter" data-level="2" data-path="setup.html"><a href="setup.html"><i class="fa fa-check"></i><b>2</b> R Fundamentals<span></span></a>
<ul>
<li class="chapter" data-level="2.1" data-path="setup.html"><a href="setup.html#functions"><i class="fa fa-check"></i><b>2.1</b> Functions<span></span></a></li>
<li class="chapter" data-level="2.2" data-path="setup.html"><a href="setup.html#exercises-2"><i class="fa fa-check"></i><b>2.2</b> Exercises 2<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="write.html"><a href="write.html"><i class="fa fa-check"></i><b>3</b> Linear Regression<span></span></a>
<ul>
<li class="chapter" data-level="3.1" data-path="write.html"><a href="write.html#estimation"><i class="fa fa-check"></i><b>3.1</b> Estimation<span></span></a></li>
<li class="chapter" data-level="3.2" data-path="write.html"><a href="write.html#exercises-1"><i class="fa fa-check"></i><b>3.2</b> Exercises 1<span></span></a></li>
<li class="chapter" data-level="3.3" data-path="write.html"><a href="write.html#inference"><i class="fa fa-check"></i><b>3.3</b> Inference<span></span></a></li>
<li class="chapter" data-level="3.4" data-path="write.html"><a href="write.html#exercises-3"><i class="fa fa-check"></i><b>3.4</b> Exercises 3<span></span></a></li>
<li class="chapter" data-level="3.5" data-path="write.html"><a href="write.html#matrix-representation"><i class="fa fa-check"></i><b>3.5</b> Matrix representation<span></span></a></li>
<li class="chapter" data-level="3.6" data-path="write.html"><a href="write.html#exercises-4"><i class="fa fa-check"></i><b>3.6</b> Exercises 4<span></span></a></li>
<li class="chapter" data-level="3.7" data-path="write.html"><a href="write.html#prediction"><i class="fa fa-check"></i><b>3.7</b> Prediction<span></span></a></li>
<li class="chapter" data-level="3.8" data-path="write.html"><a href="write.html#exercises-5"><i class="fa fa-check"></i><b>3.8</b> Exercises 5<span></span></a></li>
<li class="chapter" data-level="3.9" data-path="write.html"><a href="write.html#diagnostics"><i class="fa fa-check"></i><b>3.9</b> Diagnostics<span></span></a>
<ul>
<li class="chapter" data-level="3.9.1" data-path="write.html"><a href="write.html#residuals-as-powerful-eda-tool"><i class="fa fa-check"></i><b>3.9.1</b> Residuals as powerful EDA tool<span></span></a></li>
<li class="chapter" data-level="3.9.2" data-path="write.html"><a href="write.html#residuals-as-model-diagnostic"><i class="fa fa-check"></i><b>3.9.2</b> Residuals as model diagnostic<span></span></a></li>
</ul></li>
<li class="chapter" data-level="3.10" data-path="write.html"><a href="write.html#exercises-6"><i class="fa fa-check"></i><b>3.10</b> Exercises 6<span></span></a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ts.html"><a href="ts.html"><i class="fa fa-check"></i><b>4</b> Time Series<span></span></a>
<ul>
<li class="chapter" data-level="4.1" data-path="ts.html"><a href="ts.html#example"><i class="fa fa-check"></i><b>4.1</b> Example<span></span></a></li>
<li class="chapter" data-level="4.2" data-path="ts.html"><a href="ts.html#autocorrelation"><i class="fa fa-check"></i><b>4.2</b> Autocorrelation<span></span></a></li>
<li class="chapter" data-level="4.3" data-path="ts.html"><a href="ts.html#exercises-7"><i class="fa fa-check"></i><b>4.3</b> Exercises 7<span></span></a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://bookdown.org" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Artifex Spring 2022</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="write" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Linear Regression<a href="write.html#write" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="estimation" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Estimation<a href="write.html#estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we want to model a response variable <span class="math inline">\(Y\)</span> in terms of some predictor variables, <span class="math inline">\((X_1, X_2, X_3)\)</span>. One very general form of the model would be:</p>
<p><span class="math display">\[\begin{equation}
Y = f(X_1, X_2, X_3) + \epsilon
\end{equation}\]</span></p>
<p>where <span class="math inline">\(f\)</span> is some unknown function and <span class="math inline">\(\epsilon\)</span> is the error. Usually the exact function <span class="math inline">\(f\)</span> is unknown and we have to make assumptions about it. One such assumption is that <span class="math inline">\(f\)</span> is a linear function, which implies the following model:</p>
<p><span class="math display">\[\begin{equation}
Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2+ \beta_3 X_3 + \epsilon.
\end{equation}\]</span></p>
<p>In this model, <span class="math inline">\((\beta_0, \beta_1, \beta_2, \beta_3)\)</span> are unknown parameters. Thus, the <em>estimation</em> problem involves trying to estimate this set of coefficients.</p>
<p>Although this model may seem restrictive and simple, it is an extremely useful tool for gathering insight about data. It also introduces fundamental concepts to more complex statistical/ machine learning methods.</p>
<p><strong>Example</strong></p>
<p>Let’s do a simple example regression analysis. We will use the county dataset from the openintro package to assess the linear association between the proportion of high school graduates in a country and the proportion of the county living in poverty.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:right;">
hs_grad_2019
</th>
<th style="text-align:right;">
poverty_2019
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
88.5
</td>
<td style="text-align:right;">
15.2
</td>
</tr>
<tr>
<td style="text-align:right;">
90.8
</td>
<td style="text-align:right;">
10.4
</td>
</tr>
<tr>
<td style="text-align:right;">
73.2
</td>
<td style="text-align:right;">
30.7
</td>
</tr>
<tr>
<td style="text-align:right;">
79.1
</td>
<td style="text-align:right;">
NA
</td>
</tr>
<tr>
<td style="text-align:right;">
80.5
</td>
<td style="text-align:right;">
13.6
</td>
</tr>
<tr>
<td style="text-align:right;">
74.7
</td>
<td style="text-align:right;">
NA
</td>
</tr>
</tbody>
</table>
<p>A good first step to any analysis is to visually explore the data. For this particular case, it is hard to beat a scatterplot for visualization.</p>
<pre><code>## Warning: Removed 1876 rows containing missing values (geom_point).</code></pre>
<p><img src="series_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>It seems like fitting a linear regression to this data is reasonable. To do so, we only need a simple function in R, <code>lm</code>. Let’s fit the model and see what we get.</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
77.4447213
</td>
<td style="text-align:right;">
2.0066198
</td>
<td style="text-align:right;">
38.59462
</td>
<td style="text-align:right;">
0
</td>
</tr>
<tr>
<td style="text-align:left;">
hs_grad_2019
</td>
<td style="text-align:right;">
-0.7088124
</td>
<td style="text-align:right;">
0.0228897
</td>
<td style="text-align:right;">
-30.96645
</td>
<td style="text-align:right;">
0
</td>
</tr>
</tbody>
</table>
<p>How can we write down this model? What is the interpretation?</p>
<p>Next, we will discuss where these estimates come from.</p>
<p><strong>Estimation Details</strong></p>
<p>Let’s briefly discuss <a href="https://tutorial.math.lamar.edu/classes/calci/optimization.aspx">optimization</a>. Suppose we have the function</p>
<p><span class="math display">\[\begin{equation}
f(x) = -x^2.
\end{equation}\]</span></p>
<p>and we want to know the value of <span class="math inline">\(x\)</span> that maximizes this function. How would we do this?</p>
<p>The estimation problem in linear regression is no different. Let’s consider the simple linear regression model</p>
<p><span class="math display">\[\begin{equation}
y_i = \beta x_i + \epsilon_i.
\end{equation}\]</span></p>
<p>Our estimate of <span class="math inline">\(\beta\)</span>, which we will call <span class="math inline">\(\hat{\beta}\)</span>, will be the value of <span class="math inline">\(\beta\)</span> that minimizes the sum of squared differences between the observed and the predicted values. That is, it is the <span class="math inline">\(\beta\)</span> that minimizes this function:</p>
<p><span class="math display">\[\begin{align}
f(\beta) &amp;= \sum_i (y_i - \hat{y}_i)^2 \\
&amp;= \sum_i (y_i - \beta x_i)^2 
\end{align}\]</span></p>
<p>What is this value?</p>
</div>
<div id="exercises-1" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Exercises 1<a href="write.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Among counties with greater than 95% high school graduates, which county has the highest unemployment rate?</li>
<li>Using the command <code>data()</code>, find a dataset that interests you, generate a hypothesis regarding a linear association between two variables, and assess the hypothesis by first visualizing (using a scatterplot) and then fitting a linear regression model.</li>
<li>(Optional) Repeat the optimization analysis above for the model <span class="math inline">\(y_i = \beta_0 + \beta_1x_i\)</span>, taking partial derivatives and solving.</li>
</ol>
</div>
<div id="inference" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Inference<a href="write.html#inference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Last time, we discussed a few ways to estimate the slope coefficient in a linear regression model. This yields a point estimate. The other key ingredient for inference is to determine how much uncertainty there is in our estimate. For the case of <span class="math inline">\(\hat{\beta_1}\)</span>, we want to know how much this estimate varies from sample to sample for the specified sample size. That is, we want to know the variance of the estimate:</p>
<p><span class="math display">\[\begin{align}
Var(\hat{\beta_1}).
\end{align}\]</span></p>
<p>To find what this is, let’s just try to figure out the variance directly, using the analytic formula for <span class="math inline">\(\hat{\beta_1}\)</span> in simple linear regression:</p>
<p><span class="math display">\[\begin{align}
Var \bigg( \frac{\sum_{i=1}^n (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^n (x_i - \bar{x})^2 }  \bigg).
\end{align}\]</span></p>
<p>To carry out this calculation, recall that <span class="math inline">\(\text{var}(cx) = c^2 \text{var}(x)\)</span>. Also, recall the model assumption of independence across observations. After carrying out this calculation, we can show that,</p>
<p><span class="math display">\[\begin{equation}
Var(\hat{\beta_1}) = \frac{\hat{\sigma}^2}{(n-1) \hat{var}(x)}
\end{equation}\]</span></p>
<p>How does variation in <span class="math inline">\(\hat{\beta}\)</span> respond to changes in sample size? How about to variation in the predictor?</p>
<p>Before moving on, let’s write some code to make sure our calculations correspond with those generated by <code>lm</code>.</p>
<table style="width:88%;">
<colgroup>
<col width="25%" />
<col width="15%" />
<col width="18%" />
<col width="13%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center"> </th>
<th align="center">Estimate</th>
<th align="center">Std. Error</th>
<th align="center">t value</th>
<th align="center">Pr(&gt;|t|)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>(Intercept)</strong></td>
<td align="center">1.984</td>
<td align="center">0.0329</td>
<td align="center">60.29</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center"><strong>X</strong></td>
<td align="center">3.006</td>
<td align="center">0.03181</td>
<td align="center">94.52</td>
<td align="center">0</td>
</tr>
</tbody>
</table>
<table style="width:88%;">
<caption>Fitting linear model: y ~ X</caption>
<colgroup>
<col width="20%" />
<col width="30%" />
<col width="12%" />
<col width="23%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Observations</th>
<th align="center">Residual Std. Error</th>
<th align="center"><span class="math inline">\(R^2\)</span></th>
<th align="center">Adjusted <span class="math inline">\(R^2\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">1000</td>
<td align="center">1.04</td>
<td align="center">0.8995</td>
<td align="center">0.8994</td>
</tr>
</tbody>
</table>
<pre><code>## [1] 0.03180874</code></pre>
<p>In this case, we are able to obtain not only the variation of the estimate but also the distribution of the estimate as well as the test statistic,</p>
<p><span class="math display">\[\begin{align}
T = \frac{\hat{\beta_1} - \beta}{\sqrt{\text{var}\beta}} \sim t_{n-2}
\end{align}\]</span></p>
<p>This allows us to compute confidence intervals. For instance, if we want to compute a (1-<span class="math inline">\(\alpha\)</span>) confidence interval, note that:</p>
<p><span class="math display">\[\begin{align}
P(t_{\alpha/2} &lt; T &lt; t_{1-\alpha/2}) = (1-\alpha)
\end{align}\]</span></p>
<p><strong>Bootstrap</strong></p>
<p>In more realistic scenarios, we may not be able to obtain analytic results for the variance of an estimator. Fortunately, there are some workarounds. One such method is the bootstrap. The bootstrap is incredibly simple and effective. Let’s denote our sample as <span class="math inline">\(\mathbf{X} = (X_1,\ldots,X_n)\)</span> and the statistic as <span class="math inline">\(T(\mathbf{X})\)</span>. The algorithm consists two key steps. For <span class="math inline">\(i \in 1,\ldots,n\)</span>:</p>
<ol style="list-style-type: decimal">
<li>Resample the original data (with replacement). This results in a <em>new</em> dataset, <span class="math inline">\(\mathbf{X^\star}\)</span>, that is the same size as the original data.</li>
<li>Compute the desired statistic on the resampled data. This results in a number, <span class="math inline">\(s_i = T(\mathbf{X}^\star)\)</span></li>
</ol>
<p>This results in a sample of statistics <span class="math inline">\(\mathbf{s}=(s_1, \ldots,s_B)\)</span>. We can then estimate the variance of the statistic as the sample variance: <span class="math inline">\(\text{var}(\mathbf{s})\)</span>.</p>
<p>Let’s first do a simple example before returning to linear regression. Suppose we would like to estimate the variance of the sample mean. Let’s write a bootstrap algorithm to do this.</p>
<pre><code>## [1] 0.51801949 0.01611761</code></pre>
<p>Now, back to regression. Let’s use the same framework to estimate the variance of the slope coefficient.</p>
<pre><code>## [1] 0.03310038</code></pre>
</div>
<div id="exercises-3" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Exercises 3<a href="write.html#exercises-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p>Run the code below to simulate data from a <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distribution</a>. Generate a histogram and describe it (where is the mode? what is the skew?)</p></li>
<li><p>What is the relationship between the sample mean and median? What do you think is the relationship in the variability in these two sample statistics (i.e., if we were to draw another sample from this distribution, which one would change more on average)?</p></li>
<li><p>Using the bootstrap, generate a bootstrap sample of sample means (try to use the code above as little as possible). Use <span class="math inline">\(B = 10^4\)</span>. What is the mean and standard deviation of this sample?</p></li>
<li><p>Using the bootstrap, generate a bootstrap sample of sample medians (try to use the code above as little as possible). Use <span class="math inline">\(B = 10^4\)</span>. What is the mean and standard deviation of this sample?</p></li>
<li><p>Plot histograms of both bootstrap samples on one graphic. <a href="https://stackoverflow.com/questions/3541713/how-to-plot-two-histograms-together-in-r">See hints on this page</a></p></li>
<li><p>Going back to the hypothesis you tested in exercise 1 (question 2), estimate the standard deviation of the slope coefficient using bootstrap. How does it compare with the output generated by <code>lm</code>.</p></li>
<li><p>(Challenge question) The central limit theorem (CLT) establishes that the distribution of the sample mean is approximately normal with mean equal to the population mean and variance equal to the population variance divided by the sample size (<span class="math inline">\(\sigma^2/n\)</span>). How does the distribution of sample means generated in 3 compare with the distribution implied by the CLT? You will need to find the population mean and variance of the <a href="https://en.wikipedia.org/wiki/Gamma_distribution">gamma distribution</a> that we sampled from.</p></li>
</ol>
</div>
<div id="matrix-representation" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Matrix representation<a href="write.html#matrix-representation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s define the following matrices,</p>
<p><span class="math display">\[A = \begin{bmatrix}
7 &amp; 9\\
1 &amp; 4
\end{bmatrix} 
\qquad
B = \begin{bmatrix}
2 &amp; 1\\
3 &amp; 1
\end{bmatrix} \]</span></p>
<p>In R, input the values of a matrix by column using either <code>matrix</code> or <code>array</code>. For example, matrix <span class="math inline">\(A\)</span> above is:
<code>matrix(c(7,1,1,9,4,8,2,6,6), nrow = 3)</code> or <code>array(c(7,1,1,9,4,8,2,6,6), dim = c(3,3))</code>. Matrix operations in R include:</p>
<ol style="list-style-type: decimal">
<li><strong>Matrix addition</strong>: <span class="math inline">\(A + B\)</span>, <code>A + B</code></li>
<li><strong>Matrix multiplication</strong>: <span class="math inline">\(AB\)</span>, <code>A %*% B</code></li>
<li><strong>Inverting a matrix</strong>: <span class="math inline">\(A^{-1}\)</span>, <code>solve(A)</code></li>
<li><strong>Transposing a matrix</strong>: <span class="math inline">\(A^ \top\)</span>, <code>t(A)</code></li>
</ol>
<p>Now let’s shift a little to working with ‘general’ matrices and construct expressions for some matrix operations. In particular, let’s work with the following matrices,</p>
<p><span class="math display">\[X = \begin{bmatrix}
x_{11} &amp; x_{12}\\
x_{21} &amp; x_{22}
\end{bmatrix}
\qquad
Y = \begin{bmatrix}
y_{11} &amp; y_{12}\\
y_{21} &amp; y_{22}
\end{bmatrix} \]</span></p>
<p>Back to linear regression. By representing our model in matrix notation, we can write our model as,</p>
<p><span class="math display">\[\begin{equation}
Y = X \beta + \epsilon,
\end{equation}\]</span></p>
<p>for the case where we have <span class="math inline">\(p\)</span> predictors and <span class="math inline">\(n\)</span> observations. In this case, the design matrix <span class="math inline">\(X\)</span> has dimension <span class="math inline">\(n \times (p+1)\)</span> and <span class="math inline">\(Y\)</span> has dimension <span class="math inline">\(n \times 1\)</span>. Using this matrix representation of the model, it can be shown that the least squares estimate for <span class="math inline">\(\beta\)</span> is:</p>
<p><span class="math display">\[\begin{equation}
\hat{\beta} = (X^\top X)^{-1} (X^\top Y)
\end{equation}\]</span></p>
<p>Additionally, the variance/ covariance for <span class="math inline">\(\hat{\beta}\)</span> can be packaged up into a matrix:</p>
<p><span class="math display">\[\begin{equation}
\hat{\beta} = \sigma^2 (X^\top X)^{-1}
\end{equation}\]</span></p>
<p>For the case of SLR, the variance matrix for <span class="math inline">\((\hat{\beta_0}, \hat{\beta_1})\)</span> is:</p>
<p><span class="math display">\[Var(\hat{\boldsymbol{\beta}}) = \begin{bmatrix}
Var(\hat{\beta_0}) &amp; Cov(\hat{\beta_0}, \hat{\beta_1} )\\
Cov(\hat{\beta_0}, \hat{\beta_1} ) &amp; Var(\hat{\beta_1})
\end{bmatrix}\]</span></p>
<p>Furthermore, the matrix representation For the case of simple linear regression (SLR), is:</p>
<p><span class="math display">\[
\begin{bmatrix} 
    y_1  \\
    \vdots  \\
    y_n  
    \end{bmatrix} 
    \qquad
    = \begin{bmatrix} 
    1 &amp; x_1 \\
    \vdots &amp; \vdots \\
    1 &amp; x_n 
    \end{bmatrix}
    \begin{bmatrix} 
    \beta_0 \\
    \beta_1 
    \end{bmatrix} + 
    \begin{bmatrix}
    e_1  \\
    \vdots  \\
    e_n  
    \end{bmatrix}
\]</span></p>
</div>
<div id="exercises-4" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Exercises 4<a href="write.html#exercises-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s do some practice. For <span class="math inline">\(A, B\)</span> defined above:</p>
<p><strong>Exercises 4A</strong>2</p>
<ol style="list-style-type: decimal">
<li>What is <span class="math inline">\(AB\)</span>. Compute by hand and verify with R.</li>
<li>What is <span class="math inline">\(A^{-1}\)</span>. Compute by hand and verify with R.</li>
<li>What is <span class="math inline">\(A^\top B\)</span>. Compute by hand and verify with R.</li>
</ol>
<p><strong>Exercises 4B</strong></p>
<p>For <span class="math inline">\(X, Y\)</span> defined above:</p>
<ol style="list-style-type: decimal">
<li>What is <span class="math inline">\(X^{-1}\)</span></li>
<li>What is <span class="math inline">\(X ^ \top\)</span></li>
<li>What is <span class="math inline">\(XY\)</span> (i.e., <span class="math inline">\(X\)</span> times <span class="math inline">\(Y\)</span>; use <span class="math inline">\(\Sigma\)</span> notation)</li>
<li>What is <span class="math inline">\((XY)^{-1}\)</span></li>
</ol>
<p><strong>Exercises 4C</strong></p>
<p>The following questions pertain to the simple linear regression (SLR) case in which the design matrix, <span class="math inline">\(X\)</span>, is:</p>
<p><span class="math display">\[
    X = \begin{bmatrix} 
    1 &amp; x_1 \\
    \vdots &amp; \vdots \\
    1 &amp; x_n 
    \end{bmatrix}
\]</span></p>
<ol style="list-style-type: decimal">
<li><p>What is <span class="math inline">\(\sigma^2 (X^\top X)^{-1}\)</span>? (write it out using <span class="math inline">\(\Sigma\)</span> notation, similar to the last exercise set).</p></li>
<li><p>Take the lower right hand entry from the matrix above. Does it match what we got for <span class="math inline">\(Var(\hat{\beta_1})\)</span> in the inference section below (a little bit of simplification is required)?</p></li>
</ol>
<p><span class="math display">\[\begin{equation}
Var(\hat{\beta_1}) = \frac{\hat{\sigma}^2}{(n-1) \hat{var}(x)}
\end{equation}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>For the data below, compute (in R) the least squares estimate of <span class="math inline">\(\beta\)</span> using the expression <span class="math inline">\(\hat{\beta} = (X^\top X)^{-1} (X^\top Y)\)</span>. Verify using <code>lm</code>.</li>
</ol>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="write.html#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb10-2"><a href="write.html#cb10-2" aria-hidden="true" tabindex="-1"></a>n <span class="ot">=</span> <span class="dv">100</span></span>
<span id="cb10-3"><a href="write.html#cb10-3" aria-hidden="true" tabindex="-1"></a>X <span class="ot">=</span> <span class="fu">matrix</span>( <span class="fu">c</span>(<span class="fu">rep</span>(<span class="dv">1</span>,n), <span class="fu">rnorm</span>(n,<span class="dv">0</span>,<span class="dv">1</span>)), <span class="at">nrow =</span> n ) <span class="co"># design matrix X</span></span>
<span id="cb10-4"><a href="write.html#cb10-4" aria-hidden="true" tabindex="-1"></a>beta <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb10-5"><a href="write.html#cb10-5" aria-hidden="true" tabindex="-1"></a>y <span class="ot">=</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> X <span class="sc">%*%</span> beta, <span class="at">sd =</span> <span class="dv">3</span>)</span></code></pre></div>
<ol start="4" style="list-style-type: decimal">
<li>Finally, compute (in R) the variance matrix of <span class="math inline">\(\boldsymbol{\beta}\)</span> using <span class="math inline">\(\hat{\sigma}^2 (X^\top X)^{-1}\)</span>. The <span class="math inline">\(\hat{\sigma}^2\)</span> part is:</li>
</ol>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="write.html#cb11-1" aria-hidden="true" tabindex="-1"></a>sigsq.hat <span class="ot">=</span> <span class="fu">sum</span> ( <span class="fu">residuals</span> ( <span class="fu">lm</span>(y<span class="sc">~</span>X<span class="dv">-1</span>) ) <span class="sc">^</span><span class="dv">2</span> ) <span class="sc">/</span> (n<span class="dv">-2</span>)</span></code></pre></div>
<p>Verify that the square root of the diagonal entries of the variance matrix (<span class="math inline">\(\hat{\sigma}^2 (X^\top X)^{-1}\)</span>) equal the coefficient standard error estimates from <code>lm</code>, which you can find using the <code>summary</code> function with your fit model as the argument.</p>
<p>Though not necessary, you may find the function <code>diag</code> to be useful in extracting the diagonal entries of a matrix.</p>
</div>
<div id="prediction" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Prediction<a href="write.html#prediction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Suppose we have fit a linear regression model that predicts how much sales a certain product will generate at various price points. Your boss approaches you with a new potential price that was not observed in the data used to fit the model. Let’s call this value <span class="math inline">\(x_p\)</span>. She asks you for a prediction of the sales amount if the price is <span class="math inline">\(x_p\)</span>. Let’s call this value <span class="math inline">\(\hat{y}_p\)</span>. We can provide a point estimate as,</p>
<p><span class="math display">\[\begin{equation}
\hat{y}_p = \hat{\beta}_0 + \hat{\beta}_1 x_p.
\end{equation}\]</span></p>
<p>How much uncertainty is there in this estimate? To find out, we need to find the variance of the estimate. That is, we need,</p>
<p><span class="math display" id="eq:predvar">\[\begin{equation}
Var( \hat{\beta}_0 + \hat{\beta}_1 x_p ).
\tag{3.1}
\end{equation}\]</span></p>
<p>Recall that the coefficients depend on <span class="math inline">\(y\)</span> and are, therefore, random variables. To find the variance of the sum of two random variables, recall that for random variables <span class="math inline">\(X, Y\)</span>,</p>
<p><span class="math display">\[\begin{equation} 
Var( X + Y ) = Var(X) + Var(Y) + 2 Cov(X,Y).
\end{equation}\]</span></p>
<p>A slight modification of this result that will allow us to evaluate <a href="write.html#eq:predvar">(3.1)</a> is:</p>
<p><span class="math display">\[\begin{equation} 
Var( X + cY ) = Var(X) + c^2 Var(Y) + 2 c Cov(X,Y),
\end{equation}\]</span></p>
<p>where <span class="math inline">\(c\)</span> is a constant. Plugging in <span class="math inline">\(\hat{\beta}_0\)</span> for <span class="math inline">\(X\)</span> and <span class="math inline">\(\hat{\beta}_1\)</span> for <span class="math inline">\(Y\)</span>, we get:</p>
<p><span class="math display">\[\begin{equation} 
Var( \hat{\beta}_0 + \hat{\beta}_1 x_p ) = Var(\hat{\beta}_0) + x_p^2 Var(\hat{\beta}_1) + 2 x_p Cov(\hat{\beta}_0, \hat{\beta}_1),
\end{equation}\]</span></p>
<p>Using this expression, we can formulate a rough confidence interval for <span class="math inline">\(\hat{y}_p\)</span> as,</p>
<p><span class="math display" id="eq:confint">\[\begin{equation}
\hat{y}_p \pm 2 \times \sqrt{ Var( \hat{\beta}_0 + \hat{\beta}_1 x_p ) }
\tag{3.2}
\end{equation}\]</span></p>
<p>There is nothing special about <span class="math inline">\(x_p\)</span>. We can compute this confidence interval for any value of the predictor variable. Does the width of this band depend on <span class="math inline">\(x\)</span> at all or is the margin of error constant? Let’s explore that in the next exercise.</p>
</div>
<div id="exercises-5" class="section level2 hasAnchor" number="3.8">
<h2><span class="header-section-number">3.8</span> Exercises 5<a href="write.html#exercises-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The goal of this exercise is to generate the least squares line and confidence bands as shown in the plot below. The data used is the data generated in question 3 of exercises 4C. In other words, the end goal of the exercise is to replicate the plot below.</p>
<p>To do that, we need to compute <a href="write.html#eq:confint">(3.2)</a> for a range of <span class="math inline">\(x\)</span> values. Here are some steps to achieve this:</p>
<ol style="list-style-type: decimal">
<li>Let’s first generate the red line in the plot below. This is the least squares line. To generate this line, first generate a sequence of x-values (using the <code>seq</code> function). The range of the sequence should correspond with the range of observed values of the predictor variable. For example,</li>
</ol>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="write.html#cb12-1" aria-hidden="true" tabindex="-1"></a>xr <span class="ot">=</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">9</span>,<span class="dv">9</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span></code></pre></div>
<p>Then, for each <span class="math inline">\(x\)</span> in the sequence, generate a predicted <span class="math inline">\(y\)</span> value (i.e., <span class="math inline">\(\hat{y} = \hat{\beta_0} + \hat{\beta_1}x\)</span>). You can add this curve to your scatterplot by first generating the scatterplot (<code>plot(X[,2], y)</code>) and then adding your line using the <code>lines</code> function. The first argument to lines will be the <span class="math inline">\(x-\)</span>values (<code>xr</code> if you used the code above) and the second will be a sequence of <span class="math inline">\(\hat{y}-\)</span>values (which must be the samem length as <code>xr</code>).</p>
<p>A perhaps simpler method would be to use the <code>abline</code> function; however, using <code>lines</code> corresponds with the strategy that follows for the confidence bands.</p>
<ol start="2" style="list-style-type: decimal">
<li><p>Next, create a function that computes <a href="write.html#eq:predvar">(3.1)</a>, where <span class="math inline">\(x_p\)</span> is the function argument. Use this function for each of the <span class="math inline">\(x\)</span> values in the sequence generated above. Use this function to obtain the standard error of the estimate for each of the <span class="math inline">\(x\)</span> values in your <span class="math inline">\(x\)</span>-sequence.</p></li>
<li><p>Once you have completed the steps above, you should have a prediction and standard error for each value in the range of your <span class="math inline">\(x-\)</span>sequence (<code>xr</code> if you used the code above). The top blue curve is the prediction + 2 stanardard errors and the bottom curve is the prediction - 2 standard errors. You can again use the <code>lines</code> function to add these additional curves.</p></li>
<li><p>Where are the confidence bands widest? Why does this make intuitive sense?</p></li>
</ol>
<p><img src="series_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
</div>
<div id="diagnostics" class="section level2 hasAnchor" number="3.9">
<h2><span class="header-section-number">3.9</span> Diagnostics<a href="write.html#diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The flip-side of predictions are residuals. The predictions tells you the pattern that the model has captured, and the residuals tell you what the model has missed. The residuals are just the distances between the observed and predicted values that we computed above.</p>
<div id="residuals-as-powerful-eda-tool" class="section level3 hasAnchor" number="3.9.1">
<h3><span class="header-section-number">3.9.1</span> Residuals as powerful EDA tool<a href="write.html#residuals-as-powerful-eda-tool" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose we have a dataset of diamonds and we would like to assess the relationship between the cut of the diamond and it’s price.</p>
<p><img src="series_files/figure-html/unnamed-chunk-23-1.png" width="672" /></p>
<p>Judging from this plot, there doesn’t appear to be much of a relationship between cut and price. Maybe this is because the higher quality cuts tend to have smaller weights.</p>
<p><img src="series_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<p>There appears to be some relationship here between cut and carat, with higher quality cuts being comprised of lower weight diamonds. There is also a strong relationship between carat and price, as seen below:</p>
<p><img src="series_files/figure-html/unnamed-chunk-25-1.png" width="672" /></p>
<p>We can explore the relationship between cut and price by exploring the residuals of the model that uses only carat as a predictor and seeing how these residuals vary across cuts.</p>
<p><img src="series_files/figure-html/unnamed-chunk-26-1.png" width="672" /></p>
</div>
<div id="residuals-as-model-diagnostic" class="section level3 hasAnchor" number="3.9.2">
<h3><span class="header-section-number">3.9.2</span> Residuals as model diagnostic<a href="write.html#residuals-as-model-diagnostic" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Residuals are also a primary means of assessing the central linear regression assumption of constant variance (homoscedastic errors). We can check this assumption by plotting fitted values (<span class="math inline">\(\hat{y}\)</span>) versus residuals (<span class="math inline">\(y-\hat{y}\)</span>).</p>
<p><img src="series_files/figure-html/unnamed-chunk-27-1.png" width="672" /></p>
</div>
</div>
<div id="exercises-6" class="section level2 hasAnchor" number="3.10">
<h2><span class="header-section-number">3.10</span> Exercises 6<a href="write.html#exercises-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li><p>Explore the relationship between clarity and price in the diamonds dataset using residuals (from the linear model fit using log(price) as a response, log(carat) and cut as predictors). What are your conclusions?</p></li>
<li><p>Install the gapminder package <code>install.packages(“gapminder”)</code> and call it into your workspace using <code>library(“gapminder”)</code>. This loads a dataset named gapminder. Also use <code>library</code> to call the tidyverse package into your workspace.</p></li>
<li><p>Use the <code>filter</code> function (or other preferred method) to filter your dataset to the most recent year of data (2007) for each country.</p></li>
<li><p>Using the filtered dataset, fit a linear regression model with <strong>lifeExp</strong> as the dependent variable and <strong>gdpPercap</strong> as predictor.</p></li>
<li><p>Examine the residuals from the model fit in 4 by continent. What is your interpretation?</p></li>
<li><p>Expand your model as necessary (add predictors) and examine a residual plot of fitted values versus residuals. What is your interpretation?</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="setup.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ts.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/jules32/bookdown-tutorial/edit/master/write.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["series.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
