# Time Series {#ts}

## Example

Suppose we have data on global mean land temperature deviations (from 1951-1980 average). Let's see what this data looks like. 

```{r}
plot(globtempl, main = "Global mean land (only) temperature deviations")
```

How could we model this response. Given we only have one tool in our tool box, let's use it and fit a simple linear regression model using time as the predictor.


```{r}
data = data.frame(y = as.numeric(globtempl), x = as.numeric(time(globtempl)))

m0 = lm(y ~ x, data = data)
betas = coefficients(m0)

#summary(m0)

with(data, plot(x, y, main = "Regression of temperature deviations versus time"))
abline(betas[1], betas[2])
```

We can look at the residuals from this model as a quick diagnostic.

```{r}
plot(y = residuals(m0), x = as.numeric(time(globtempl)),
     main = "Residuals of Simple Linear Regression")
abline(a=0, b=0)
```

Perhaps we should use a time series model instead in which current values of the series are modelled as a function of past values. That is,

\begin{equation}
y_t = \delta + \phi y_{t-1} + \epsilon_t.
(\#eq:armod)
\end{equation}

In order to satisfy the assumptions of such a model, however, we need our time series to be (weakly) stationary. A series  is said to be (weakly) stationary if it satisfies the following properties:

- The mean  is the same for all $y_t$.
- The variance of  is the same for all $y_t$.
- The covariance (and also correlation) between  and  is the same for all  at each lag  $h = 1, 2, 3$, etc.

Does our time series satisfy this condition? Maybe if we do a transformation, we can satisfy the condition. Let's take the <code>diff</code>. That is, let,

\begin{equation}
x_t = y_t -  y_{t-1}.
\end{equation}

Let's examine a plot of these differences.


```{r}
y = diff(globtempl)
plot(y, main = "Differences in temperature deviations")
```

This looks decently stationary. Let's fit a model of the form \@ref(eq:armod) to the differences data. This can be achieved with the <code>arima</code> function.

```{r echo=TRUE}
m0 = arima(diff(globtempl), order = c(1,0,0))
#summary(m0)
```

Let's look at the predicted versus actual values from this model.

```{r}
fx = y - m0$residuals

fx.orig = globtempl + fx

g2 = window(globtempl, start = 1881)
plot(fx.orig, col = "red", ylab = "temp deviations", main = "Predicted (red) versus actual (blue) values")
lines(g2, col = "blue")
```

This certainly looks like an improvement over linear regression!

## Autocorrelation

A central concept in time series analysis is autocorrelation. This is the correlation between $y_t$ and its lagged value. For a lag of $h$, this is the correlation between $y_t$ and $y_{t-h}$. For the differenced series above, this can be found using the <code>acf</code> function.

```{r}
acf(y)
```


## Exercises 7

Write your own program to plot the autocorrelation function of a given series of values for a specified number of lags. The code below computes the lag 1 autocorrelation for the time series analysed above, $y$:

```{r echo=TRUE }
h = 1 # how many lags
cor.df = data.frame(y = as.numeric(y), y1 = c(window(y, start = start(y)[1] + h), rep(0, h)) ) # cor(y, y-h)
acxf_lagh = with(cor.df[- ( (length(y) - h + 1):length(y)) ,], cor(y, y1)) # cor(y, y-h)
```

















